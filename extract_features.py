import os
import json
import torch
import numpy as np
from PIL import Image
from tqdm import tqdm
from diffusers import AutoencoderKL
from torchvision import transforms
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# ===== args =====
import argparse
parser = argparse.ArgumentParser()
parser.add_argument("--method", type=str, default="shape",
                    help="åˆ†é¡æ–¹æ³•åç¨±ï¼Œdecoraction / dynasty / glaze / kiln / shape")
args = parser.parse_args()
CLASSIFICATION_METHOD = args.method
# =====================

# ===== æ‰‹å‹•è¨­å®š =====
DATA_FILE = f"./data/{CLASSIFICATION_METHOD}.json"
IMAGE_DIR = "./picture"
OUT_DIR = f"./features/{CLASSIFICATION_METHOD}"
OUT_FILE = os.path.join(OUT_DIR, "features.npz")
PCA_FILE = os.path.join(OUT_DIR, "pca_features.npz")
PCA_COMPONENTS = 50
MODEL_NAME = "stabilityai/sd-vae-ft-mse"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
RANDOM_STATE = 42
# ===================

def load_vae(model_name=MODEL_NAME):
    print(f"ğŸ§  è¼‰å…¥ VAE: {model_name} åˆ° {DEVICE} ...")
    model = AutoencoderKL.from_pretrained(model_name)
    model.to(DEVICE)
    model.eval()
    return model

def get_transform():
    return transforms.Compose([
        transforms.Resize((512, 512)),
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # to [-1,1]
    ])

def extract_feature(img_path, model, transform):
    try:
        img = Image.open(img_path).convert("RGB")
        tensor = transform(img).unsqueeze(0).to(DEVICE)
        with torch.no_grad():
            enc = model.encode(tensor)
            latent = enc.latent_dist.mean
            feat = latent.cpu().numpy().reshape(-1)
        return feat
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•è™•ç†åœ–ç‰‡ {img_path}: {e}")
        return None

def main():
    os.makedirs(OUT_DIR, exist_ok=True)

    with open(DATA_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)

    vae = load_vae()
    transform = get_transform()

    features, labels, ids, missing = [], [], [], []

    print(f"ğŸ“¦ é–‹å§‹å¾ {IMAGE_DIR} æŠ½å–ç‰¹å¾µï¼Œå…± {len(data)} é …...")
    for item in tqdm(data):
        if "class" not in item:
            missing.append(item.get("identifier", "N/A"))
            continue

        img_path = os.path.join(IMAGE_DIR, f"{item['identifier']}.jpg")
        if not os.path.exists(img_path):
            missing.append(item.get("identifier", "N/A"))
            continue

        feat = extract_feature(img_path, vae, transform)
        if feat is not None:
            features.append(feat)
            labels.append(item["class"])
            ids.append(item["identifier"])
        else:
            missing.append(item.get("identifier", "N/A"))

    if not features:
        print("âŒ æœªæŠ½å–åˆ°ä»»ä½•ç‰¹å¾µï¼Œè«‹ç¢ºèªåœ–ç‰‡å­˜åœ¨ä¸¦å¯è®€å–ã€‚")
        return

    features = np.stack(features, axis=0)  # (N, D)
    class_names = sorted(list(set(labels)))

    # === å„²å­˜åŸå§‹ç‰¹å¾µ ===
    np.savez_compressed(
        OUT_FILE,
        features=features,
        labels=np.array(labels, dtype=object),
        ids=np.array(ids, dtype=object),
        class_names=np.array(class_names, dtype=object)
    )
    print(f"âœ… åŸå§‹ç‰¹å¾µå·²å„²å­˜ï¼š{OUT_FILE}")

    # === æ¨™æº–åŒ– + PCA é™ç¶­ ===
    print("âš™ï¸ åŸ·è¡Œæ¨™æº–åŒ– (StandardScaler) ...")
    scaler = StandardScaler()
    Xs = scaler.fit_transform(features)

    pca_components = min(PCA_COMPONENTS, Xs.shape[1])
    print(f"âš™ï¸ åŸ·è¡Œ PCA -> {pca_components} components ...")
    pca = PCA(n_components=pca_components, random_state=RANDOM_STATE)
    X_pca = pca.fit_transform(Xs)

    np.save(os.path.join(OUT_DIR, "pca_components.npy"), pca.components_)
    np.savez_compressed(
        PCA_FILE,
        features=X_pca,
        labels=np.array(labels, dtype=object),
        ids=np.array(ids, dtype=object),
        class_names=np.array(class_names, dtype=object)
    )
    np.save(os.path.join(OUT_DIR, "scaler_mean.npy"), scaler.mean_)
    np.save(os.path.join(OUT_DIR, "scaler_scale.npy"), scaler.scale_)

    print(f"âœ… PCA ç‰¹å¾µå·²å„²å­˜ï¼š{PCA_FILE}")

    if missing:
        print(f"âš ï¸ æœ‰ {len(missing)} å¼µåœ–ç‰‡ç¼ºå¤±æˆ–ç„¡æ³•è™•ç†ï¼š")
        print(missing[:50])

if __name__ == "__main__":
    main()
